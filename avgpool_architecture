digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2581814940672 [label="
 (1, 10)" fillcolor=darkolivegreen1]
	2581814830336 [label=AddmmBackward0]
	2581814823616 -> 2581814830336
	2576733732000 [label="fc_layers.4.bias
 (10)" fillcolor=lightblue]
	2576733732000 -> 2581814823616
	2581814823616 [label=AccumulateGrad]
	2574824865408 -> 2581814830336
	2574824865408 [label=MulBackward0]
	2574824852736 -> 2574824865408
	2574824852736 [label=ReluBackward0]
	2574824859792 -> 2574824852736
	2574824859792 [label=AddmmBackward0]
	2581814897744 -> 2574824859792
	2576733731680 [label="fc_layers.1.bias
 (128)" fillcolor=lightblue]
	2576733731680 -> 2581814897744
	2581814897744 [label=AccumulateGrad]
	2581814896976 -> 2574824859792
	2581814896976 [label=ViewBackward0]
	2581814898224 -> 2581814896976
	2581814898224 [label=AvgPool2DBackward0]
	2581814898464 -> 2581814898224
	2581814898464 [label=MulBackward0]
	2581814898512 -> 2581814898464
	2581814898512 [label=ReluBackward0]
	2581814898656 -> 2581814898512
	2581814898656 [label=ConvolutionBackward0]
	2581814898752 -> 2581814898656
	2581814898752 [label=AvgPool2DBackward0]
	2581814898944 -> 2581814898752
	2581814898944 [label=MulBackward0]
	2581814899040 -> 2581814898944
	2581814899040 [label=ReluBackward0]
	2581814899136 -> 2581814899040
	2581814899136 [label=ConvolutionBackward0]
	2581814899232 -> 2581814899136
	2581814939792 [label="
 (1, 3, 64, 64)" fillcolor=lightblue]
	2581814939792 -> 2581814899232
	2581814899232 [label=AccumulateGrad]
	2581814899280 -> 2581814899136
	2573632145280 [label="conv_layers.0.weight
 (8, 3, 3, 3)" fillcolor=lightblue]
	2573632145280 -> 2581814899280
	2581814899280 [label=AccumulateGrad]
	2581814898896 -> 2581814899136
	2573632158400 [label="conv_layers.0.bias
 (8)" fillcolor=lightblue]
	2573632158400 -> 2581814898896
	2581814898896 [label=AccumulateGrad]
	2581814898800 -> 2581814898656
	2573632158320 [label="conv_layers.4.weight
 (16, 8, 3, 3)" fillcolor=lightblue]
	2573632158320 -> 2581814898800
	2581814898800 [label=AccumulateGrad]
	2581814898128 -> 2581814898656
	2573632151600 [label="conv_layers.4.bias
 (16)" fillcolor=lightblue]
	2573632151600 -> 2581814898128
	2581814898128 [label=AccumulateGrad]
	2581814897840 -> 2574824859792
	2581814897840 [label=TBackward0]
	2581814898608 -> 2581814897840
	2573632151520 [label="fc_layers.1.weight
 (128, 4096)" fillcolor=lightblue]
	2573632151520 -> 2581814898608
	2581814898608 [label=AccumulateGrad]
	2574824860608 -> 2581814830336
	2574824860608 [label=TBackward0]
	2574824855184 -> 2574824860608
	2576733730960 [label="fc_layers.4.weight
 (10, 128)" fillcolor=lightblue]
	2576733730960 -> 2574824855184
	2574824855184 [label=AccumulateGrad]
	2581814830336 -> 2581814940672
}
